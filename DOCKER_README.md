# ğŸ³ Urology Inference Holoscan C++ - Docker éƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—èªªæ˜å¦‚ä½•ä½¿ç”¨ Docker å®¹å™¨é‹è¡ŒåŸºæ–¼ NVIDIA Holoscan SDK 3.3.0 çš„ Urology Inference æ‡‰ç”¨ç¨‹åºã€‚

## ğŸ“‹ å‰ç½®éœ€æ±‚

### ç¡¬ä»¶éœ€æ±‚
- **GPU**: NVIDIA GPU (æ¨è–¦ RTX 30ç³»åˆ—æˆ–æ›´æ–°)
- **å…§å­˜**: æœ€å°‘ 8GB RAM
- **å­˜å„²**: æœ€å°‘ 10GB å¯ç”¨ç©ºé–“

### è»Ÿä»¶éœ€æ±‚
- **Docker**: 20.10+ 
- **Docker Compose**: 2.0+
- **NVIDIA Container Toolkit**: æœ€æ–°ç‰ˆæœ¬
- **NVIDIA é©…å‹•**: 525+ (æ”¯æ´ CUDA 12.0+)

### å®‰è£ NVIDIA Container Toolkit

```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. ä½¿ç”¨ Docker Compose (æ¨è–¦)

```bash
# å…‹éš†é …ç›®
git clone <repository>
cd urology-inference-holoscan-cpp

# é‹è¡Œç”Ÿç”¢ç’°å¢ƒ
docker-compose up urology-inference

# é‹è¡Œé–‹ç™¼ç’°å¢ƒ
docker-compose --profile development up urology-inference-dev
```

### 2. ä½¿ç”¨æ§‹å»ºè…³æœ¬

```bash
# æ§‹å»ºé‹è¡Œæ™‚é¡åƒ
./scripts/docker-build.sh --runtime --release

# æ§‹å»ºé–‹ç™¼é¡åƒ
./scripts/docker-build.sh --development --debug

# æ§‹å»ºæ‰€æœ‰é¡åƒ
./scripts/docker-build.sh --all
```

### 3. ç›´æ¥ä½¿ç”¨ Docker

```bash
# æ§‹å»ºé¡åƒ
docker build -t urology-inference:runtime --target runtime .

# é‹è¡Œå®¹å™¨
docker run --gpus all -it urology-inference:runtime --help
```

## ğŸ—ï¸ å¤šéšæ®µæ§‹å»ºæ¶æ§‹

### Runtime Stage (ç”Ÿç”¢ç’°å¢ƒ)
```dockerfile
FROM nvcr.io/nvidia/clara-holoscan/holoscan:v3.3.0-dgpu
```
- æœ€å°åŒ–çš„é‹è¡Œæ™‚ç’°å¢ƒ
- åªåŒ…å«å¿…è¦çš„é‹è¡Œæ™‚ä¾è³´
- å„ªåŒ–çš„æ‡‰ç”¨ç¨‹åºäºŒé€²åˆ¶æ–‡ä»¶
- é¡åƒå¤§å°: ~2-3GB

### Development Stage (é–‹ç™¼ç’°å¢ƒ)
```dockerfile
FROM nvcr.io/nvidia/clara-holoscan/holoscan:v3.3.0-dgpu
```
- å®Œæ•´çš„é–‹ç™¼å·¥å…·éˆ
- åŒ…å«èª¿è©¦å·¥å…·å’Œåˆ†æå™¨
- æ”¯æŒå¯¦æ™‚ä»£ç¢¼ç·¨è¼¯
- é¡åƒå¤§å°: ~5-6GB

## ğŸ“Š Docker Compose æœå‹™

### ç”Ÿç”¢æœå‹™ (`urology-inference`)
```yaml
# é‹è¡Œç”Ÿç”¢æ‡‰ç”¨
docker-compose up urology-inference
```

**ç‰¹æ€§**:
- GPU åŠ é€Ÿæ¨ç†
- æŒä¹…åŒ–æ—¥èªŒå’Œè¼¸å‡º
- å¥åº·æª¢æŸ¥
- è³‡æºé™åˆ¶
- å®‰å…¨é…ç½®

### é–‹ç™¼æœå‹™ (`urology-inference-dev`)
```yaml
# é€²å…¥é–‹ç™¼æ¨¡å¼
docker-compose --profile development up urology-inference-dev
```

**ç‰¹æ€§**:
- æºä»£ç¢¼å·æ›è¼‰
- äº¤äº’å¼ shell
- èª¿è©¦å·¥å…·æ”¯æŒ
- æ§‹å»ºç·©å­˜

### æ¸¬è©¦æœå‹™ (`urology-inference-test`)
```yaml
# é‹è¡Œæ¸¬è©¦
docker-compose --profile testing up urology-inference-test
```

### åŸºæº–æ¸¬è©¦æœå‹™ (`urology-inference-benchmark`)
```yaml
# é‹è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦
docker-compose --profile benchmarking up urology-inference-benchmark
```

## ğŸ”§ é…ç½®å’Œå·æ›è¼‰

### ç’°å¢ƒè®Šæ•¸
```bash
# æ ¸å¿ƒè·¯å¾‘é…ç½®
HOLOHUB_DATA_PATH=/app/data
HOLOSCAN_MODEL_PATH=/app/models
UROLOGY_CONFIG_PATH=/app/config
UROLOGY_LOG_PATH=/app/logs
UROLOGY_OUTPUT_PATH=/app/output

# æ‡‰ç”¨é…ç½®
UROLOGY_RECORD_OUTPUT=true
UROLOGY_INFERENCE_BACKEND=trt

# GPU é…ç½®
NVIDIA_VISIBLE_DEVICES=all
CUDA_VISIBLE_DEVICES=all
```

### å·æ›è¼‰é…ç½®
```yaml
volumes:
  # è¼¸å…¥æ•¸æ“š (åªè®€)
  - ./data:/app/data:ro
  - ./models:/app/models:ro
  - ./config:/app/config:ro
  
  # è¼¸å‡ºæ•¸æ“š (è®€å¯«)
  - urology_logs:/app/logs
  - urology_output:/app/output
```

### ç›®éŒ„çµæ§‹
```
urology-inference-holoscan-cpp/
â”œâ”€â”€ data/                    # è¼¸å…¥æ•¸æ“š
â”‚   â”œâ”€â”€ inputs/             # è¦–é »/åœ–åƒè¼¸å…¥
â”‚   â””â”€â”€ models/             # æ¨ç†æ¨¡å‹
â”œâ”€â”€ config/                 # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ app_config.yaml
â”‚   â””â”€â”€ labels.yaml
â”œâ”€â”€ models/                 # é¡å¤–æ¨¡å‹æ–‡ä»¶
â””â”€â”€ logs/                   # æ‡‰ç”¨æ—¥èªŒ (å®¹å™¨å‰µå»º)
```

## ğŸ® ä½¿ç”¨æŒ‡å—

### åŸºæœ¬å‘½ä»¤

```bash
# æŸ¥çœ‹å¹«åŠ©
docker run --gpus all urology-inference:runtime help

# æª¢æŸ¥ç’°å¢ƒ
docker run --gpus all urology-inference:runtime env

# æŸ¥çœ‹ç‰ˆæœ¬
docker run --gpus all urology-inference:runtime version

# æª¢æŸ¥ä¾è³´
docker run --gpus all urology-inference:runtime verify-deps

# é‹è¡Œæ¨ç†
docker run --gpus all \
  -v $(pwd)/data:/app/data:ro \
  -v $(pwd)/models:/app/models:ro \
  urology-inference:runtime \
  --source replayer \
  --record_output true
```

### é–‹ç™¼æ¨¡å¼

```bash
# é€²å…¥é–‹ç™¼å®¹å™¨
docker-compose --profile development run --rm urology-inference-dev

# åœ¨å®¹å™¨å…§ç·¨è­¯
./scripts/build_optimized.sh --debug --enable-testing

# é‹è¡Œæ¸¬è©¦
cd build && ctest --output-on-failure
```

### æ¸¬è©¦å’ŒåŸºæº–æ¸¬è©¦

```bash
# é‹è¡Œå–®å…ƒæ¸¬è©¦
docker run --gpus all urology-inference:runtime test

# é‹è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦
docker run --gpus all urology-inference:runtime benchmark

# æŸ¥çœ‹æ¸¬è©¦çµæœ
docker run --gpus all \
  -v urology_test_results:/results \
  urology-inference:runtime \
  cat /results/test_report.xml
```

## ğŸ“Š ç›£æ§å’Œæ—¥èªŒ

### æ—¥èªŒè¨ªå•
```bash
# æŸ¥çœ‹å¯¦æ™‚æ—¥èªŒ
docker-compose logs -f urology-inference

# æŸ¥çœ‹å®¹å™¨å…§æ—¥èªŒ
docker exec -it urology-inference-runtime tail -f /app/logs/urology_*.log
```

### æ€§èƒ½ç›£æ§
```bash
# GPU ä½¿ç”¨æƒ…æ³
docker exec -it urology-inference-runtime nvidia-smi

# å®¹å™¨è³‡æºä½¿ç”¨
docker stats urology-inference-runtime

# æ‡‰ç”¨æ€§èƒ½æŒ‡æ¨™
docker exec -it urology-inference-runtime \
  ./urology_inference_holoscan_cpp --monitor-performance
```

### å¥åº·æª¢æŸ¥
```bash
# æª¢æŸ¥å®¹å™¨å¥åº·ç‹€æ…‹
docker inspect --format='{{.State.Health.Status}}' urology-inference-runtime

# æŸ¥çœ‹å¥åº·æª¢æŸ¥æ—¥èªŒ
docker inspect --format='{{range .State.Health.Log}}{{.Output}}{{end}}' urology-inference-runtime
```

## ğŸ” ä¾è³´é©—è­‰

### è¦–é »ç·¨ç¢¼å™¨ä¾è³´æª¢æŸ¥

é …ç›®åŒ…å«å®Œæ•´çš„è¦–é »ç·¨ç¢¼å™¨ä¾è³´é©—è­‰æ©Ÿåˆ¶ï¼Œç¢ºä¿æ‰€æœ‰ GXF å¤šåª’é«”æ“´å±•æ­£ç¢ºå®‰è£ï¼š

```bash
# åœ¨å®¹å™¨ä¸­é©—è­‰ä¾è³´
docker run --gpus all urology-inference:runtime verify-deps

# æˆ–ä½¿ç”¨ Docker Compose
docker-compose run --rm urology-inference verify-deps

# è©³ç´°é©—è­‰ä¿¡æ¯
docker run --gpus all urology-inference:runtime verify-deps --verbose
```

### è‡ªå‹•é©—è­‰

- **æ§‹å»ºæ™‚é©—è­‰**: Docker æ§‹å»ºéç¨‹ä¸­è‡ªå‹•å®‰è£å’Œé©—è­‰ä¾è³´
- **å•Ÿå‹•æ™‚æª¢æŸ¥**: å®¹å™¨å•Ÿå‹•æ™‚è‡ªå‹•æª¢æŸ¥é—œéµä¾è³´
- **å¥åº·æª¢æŸ¥**: Docker Compose å¥åº·æª¢æŸ¥åŒ…å«ä¾è³´é©—è­‰

### é©—è­‰å…§å®¹

âœ… **GXF å¤šåª’é«”æ“´å±•**
- libgxf_encoder.so (H.264/H.265 ç·¨ç¢¼)
- libgxf_encoderio.so (ç·¨ç¢¼å™¨ I/O æ“ä½œ)
- libgxf_decoder.so (è¦–é »è§£ç¢¼)
- libgxf_decoderio.so (è§£ç¢¼å™¨ I/O æ“ä½œ)

âœ… **ç³»çµ±ä¾è³´**
- NVIDIA é©…å‹•æª¢æŸ¥
- CUDA é‹è¡Œæ™‚æª¢æŸ¥
- Holoscan SDK ç‰ˆæœ¬é©—è­‰

âœ… **åº«ä¾è³´**
- å‹•æ…‹éˆæ¥åº«å®Œæ•´æ€§
- æ¬Šé™å’Œå¯è®€æ€§æª¢æŸ¥
- æ–‡ä»¶å¤§å°é©—è­‰

### æ‰‹å‹•é©—è­‰

å¦‚æœéœ€è¦åœ¨ä¸»æ©Ÿç³»çµ±ä¸Šé©—è­‰ï¼š

```bash
# ç›´æ¥é‹è¡Œé©—è­‰è…³æœ¬
./scripts/verify_video_encoder_deps.sh

# è©³ç´°æ¨¡å¼
./scripts/verify_video_encoder_deps.sh --verbose

# è‡ªå®šç¾©åº«è·¯å¾‘
./scripts/verify_video_encoder_deps.sh --libs-dir /custom/path/to/holoscan/lib
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

**1. GPU ä¸å¯ç”¨**
```bash
# æª¢æŸ¥ NVIDIA é‹è¡Œæ™‚
docker info | grep nvidia

# æ¸¬è©¦ GPU è¨ªå•
docker run --gpus all nvidia/cuda:12.0-runtime-ubuntu20.04 nvidia-smi
```

**2. å…§å­˜ä¸è¶³**
```bash
# å¢åŠ  Docker å…§å­˜é™åˆ¶
docker-compose up --memory=8g urology-inference
```

**3. æ¬Šé™å•é¡Œ**
```bash
# æª¢æŸ¥å·æ›è¼‰æ¬Šé™
ls -la data/ models/ config/

# ä¿®å¾©æ¬Šé™
sudo chown -R $USER:$USER data/ models/ config/
```

### èª¿è©¦æ¨¡å¼

```bash
# é€²å…¥å®¹å™¨ shell
docker run --gpus all -it urology-inference:runtime shell

# é‹è¡Œèª¿è©¦ç‰ˆæœ¬
docker-compose --profile development run --rm urology-inference-dev gdb ./build/urology_inference_holoscan_cpp
```

### æ—¥èªŒåˆ†æ

```bash
# æª¢æŸ¥æ§‹å»ºæ—¥èªŒ
docker-compose build --no-cache urology-inference 2>&1 | tee build.log

# åˆ†æé‹è¡Œæ™‚éŒ¯èª¤
docker-compose logs urology-inference | grep ERROR

# å°å‡ºæ€§èƒ½æ—¥èªŒ
docker cp urology-inference-runtime:/app/logs ./exported_logs/
```

## ğŸš€ ç”Ÿç”¢éƒ¨ç½²

### è³‡æºé…ç½®
```yaml
# docker-compose.prod.yml
services:
  urology-inference:
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8'
        reservations:
          memory: 8G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu, compute, video]
```

### å®‰å…¨é…ç½®
```yaml
security_opt:
  - no-new-privileges:true
  - seccomp:unconfined  # å¦‚æœéœ€è¦ç‰¹æ®Šç³»çµ±èª¿ç”¨
read_only: true
tmpfs:
  - /tmp:size=1G
user: 1001:1001
```

### æŒä¹…åŒ–å­˜å„²
```yaml
volumes:
  urology_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /storage/urology-inference
```

## ğŸ“ˆ æ€§èƒ½å„ªåŒ–

### æ§‹å»ºå„ªåŒ–
```bash
# ä½¿ç”¨ BuildKit
export DOCKER_BUILDKIT=1

# å¤šéšæ®µç·©å­˜
docker build --cache-from urology-inference:builder --target runtime .

# ä¸¦è¡Œæ§‹å»º
docker buildx build --platform linux/amd64 --load .
```

### é‹è¡Œæ™‚å„ªåŒ–
```yaml
# æ¸›å°‘å•Ÿå‹•æ™‚é–“
environment:
  - NVIDIA_DRIVER_CAPABILITIES=compute,video
  - CUDA_CACHE_DISABLE=0

# å„ªåŒ–å…§å­˜ä½¿ç”¨
shm_size: 2g
ulimits:
  memlock:
    soft: -1
    hard: -1
```

## ğŸ“ æœ€ä½³å¯¦è¸

1. **é¡åƒç®¡ç†**
   - ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬æ¨™ç±¤
   - å®šæœŸæ¸…ç†æœªä½¿ç”¨çš„é¡åƒ
   - å¯¦æ–½é¡åƒæƒæ

2. **æ•¸æ“šç®¡ç†**
   - ä½¿ç”¨å‘½åå·é€²è¡ŒæŒä¹…åŒ–
   - å®šæœŸå‚™ä»½é‡è¦æ•¸æ“š
   - ç›£æ§å­˜å„²ä½¿ç”¨æƒ…æ³

3. **å®‰å…¨**
   - ä¸ä»¥ root ç”¨æˆ¶é‹è¡Œ
   - ä½¿ç”¨åªè®€æ ¹æ–‡ä»¶ç³»çµ±
   - é™åˆ¶å®¹å™¨èƒ½åŠ›

4. **ç›£æ§**
   - å¯¦æ–½å¥åº·æª¢æŸ¥
   - ç›£æ§è³‡æºä½¿ç”¨
   - è¨­ç½®æ—¥èªŒè¼ªæ›

## ğŸ”— ç›¸é—œè³‡æº

- [NVIDIA Holoscan Documentation](https://docs.nvidia.com/holoscan/)
- [Docker GPU Support](https://docs.docker.com/config/containers/resource_constraints/#gpu)
- [NVIDIA Container Toolkit](https://github.com/NVIDIA/nvidia-container-toolkit)
- [Docker Compose GPU](https://docs.docker.com/compose/gpu-support/)

---

**ç¶­è­·è€…**: Urology Inference Team  
**ç‰ˆæœ¬**: 1.0.0  
**åŸºæ–¼**: NVIDIA Holoscan SDK 3.3.0 